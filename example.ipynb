{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "if not os.path.exists(\"./data\"):\n",
    "    raise ValueError('You need to import the data first, run load_data.py')\n",
    "else:\n",
    "    #df = pd.read_csv('data/iris_data.csv',sep='\\t')\n",
    "    df = pd.read_csv('data/data_titanic.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       0.000000\n",
       "pclass         0.000000\n",
       "sex            0.000000\n",
       "age            0.198653\n",
       "sibsp          0.000000\n",
       "parch          0.000000\n",
       "fare           0.000000\n",
       "embarked       0.002245\n",
       "class          0.000000\n",
       "who            0.000000\n",
       "adult_male     0.000000\n",
       "deck           0.772166\n",
       "embark_town    0.002245\n",
       "alive          0.000000\n",
       "alone          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#report nans\n",
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions for preprocessing\n",
    "\n",
    "#check for duplicates\n",
    "def check_duplicates(df):\n",
    "    has_dup = df.duplicated()\n",
    "    true_dup = np.where(has_dup == True)\n",
    "    if len(true_dup[0]) > 0:\n",
    "        print(\"Data has\", len(true_dup[0]), \"duplicates\")\n",
    "    else:\n",
    "        print(\"No duplicates found\")\n",
    "\n",
    "#function for one-hot encoding\n",
    "def one_hot(df, column_names):\n",
    "    for col in column_names:\n",
    "        dummies = pd.get_dummies(df[[col]].astype('category'))\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df\n",
    "\n",
    "#function for adding interaction terms\n",
    "def add_interactions(df,degree=2):\n",
    "    poly = PolynomialFeatures(interaction_only=True, include_bias=False, degree=degree)\n",
    "    X_poly = poly.fit_transform(df)\n",
    "    column_names = list(poly.get_feature_names_out())\n",
    "    X_poly = pd.DataFrame(X_poly,columns=column_names)\n",
    "    return X_poly\n",
    "\n",
    "#function for computing sigmoid (e.g. to look at logistic regression fit)\n",
    "def sigmoid(x,b):\n",
    "    return 1 / (1 + np.exp(-(b+x)))\n",
    "\n",
    "#min-max scale vector to pre-specified range\n",
    "def linmap(vector, new_min, new_max):\n",
    "    vector = np.array(vector)\n",
    "    old_min = np.min(vector)\n",
    "    old_max = np.max(vector)\n",
    "    \n",
    "    # Avoid division by zero if the old_min equals old_max\n",
    "    if old_min == old_max:\n",
    "        return np.full_like(vector, new_min if old_min == old_max else new_max)\n",
    "    \n",
    "    # Scale the vector\n",
    "    scaled_vector = (vector - old_min) / (old_max - old_min) * (new_max - new_min) + new_min\n",
    "    return scaled_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 107 duplicates\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm',\\n       'petal_width_cm'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[0;32m     36\u001b[0m scaler\u001b[38;5;241m.\u001b[39mset_output(transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns_to_scale\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     39\u001b[0m X_test_scaled  \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test[columns_to_scale])\n\u001b[0;32m     40\u001b[0m X_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_train_scaled, X_train\u001b[38;5;241m.\u001b[39mdrop(columns_to_scale,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\DATA\\DS-bootcamp\\EDA_skeletonscripts\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\DATA\\DS-bootcamp\\EDA_skeletonscripts\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\DATA\\DS-bootcamp\\EDA_skeletonscripts\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm',\\n       'petal_width_cm'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "target_column = 'survived'\n",
    "#target_column = 'target'\n",
    "\n",
    "\n",
    "### main preprocessing function:\n",
    "\n",
    "## done on train and test set together\n",
    "#clean up column names\n",
    "df.columns = [col.replace(' ', '_') for col in df.columns]\n",
    "df.columns = [col.replace('(',  '') for col in df.columns]\n",
    "df.columns = [col.replace(')',  '') for col in df.columns]\n",
    "\n",
    "#check and report on duplicate data\n",
    "check_duplicates(df)\n",
    "\n",
    "# Checking for data imbalance\n",
    "df[target_column].value_counts()\n",
    "\n",
    "#non-linear scaling of values\n",
    "\n",
    "#run train-test split\n",
    "X = df\n",
    "X_train, X_test, _, _ = train_test_split(X, df[target_column], random_state=1234) #note: X still contains the y-variable in the 'target' column\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "## done separately for train and test\n",
    "\n",
    "#imputing\n",
    "\n",
    "#remove outliers from the training set\n",
    "\n",
    "#range normalization\n",
    "columns_to_scale = ['sepal_length_cm', 'sepal_width_cm','petal_length_cm','petal_width_cm']\n",
    "scaler = MinMaxScaler()\n",
    "scaler.set_output(transform=\"pandas\")\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test_scaled  = scaler.transform(X_test[columns_to_scale])\n",
    "X_train = pd.concat([X_train_scaled, X_train.drop(columns_to_scale,axis=1)], axis=1)\n",
    "X_test  = pd.concat([X_test_scaled, X_test.drop(columns_to_scale,axis=1)], axis=1)\n",
    "\n",
    "#X_train        = np.concatenate([X_train_scaled, X_train.drop(columns_to_scale, axis=1)], axis=1)\n",
    "#X_test         = np.concatenate([X_test_scaled, X_test.drop(columns_to_scale, axis=1)], axis=1)\n",
    "\n",
    "#separate the target\n",
    "y_train = X_train[target_column]\n",
    "X_train = X_train.drop(target_column,axis=1)\n",
    "y_test = X_test[target_column]\n",
    "X_test = X_test.drop(target_column,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode categorical variables\n",
    "\n",
    "#add interaction terms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
